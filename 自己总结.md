**线性变换**：

矩阵的列可以看作是变换后的基向量
把矩阵向量乘法看作它们的线性组合

复合变换：n个独立的变换（前者旋转90度，后者是一个shear....）
矩阵与矩阵相乘有着几何意义，也就是==两个线性变换相继作用==
![image-20250410193459999](/Users/ianzhao/Desktop/MIT-Linear-Algebra-Notes/自己总结.assets/image-20250410193459999.png)

Rotaion的两个基 （0，1） （-1，0）， 分布在前面矩阵的作用下变换为 （1，1） （-1，0）

**一组基底直接围成的面积/体积经过线性变换之后单位面积/体积缩放的比例，称之为Determinant**
假设一个矩阵的行列式是3，意味着它将一个区域的面积增加为原来的3倍
行列式为0意味着把原来的体积压缩成更低的维度（线面点），任何区域的体积为0



==矩阵A的逆A^-1^意味着与原先A的线性变换相反的操作==
A^-1^A等于一个“什么都不做”的矩阵=恒等变换
只要变换A不把空间压缩到一个低维度的空间，那么det(A)不等于0，A^-1^存在

==如果A的行列式为0，意味着压缩到一个低维度的空间，你不能把一个低维度的空间返回到高维度的，因此就不存在A^-1^==

当一个线性变换把空间转变成一条线（一维），那么称rank(A)=1, 如果变换后的向量都落在平面上，那么称rank(A)=2
==RANK代表着变换后空间的维数==

列空间就是矩阵的列span的空间

==dim(column space)=RANK==

Rank如果与列数相等，那么称之为full rank
原点0一直是在column space中的
==变换后落在原点(零向量）的向量的集合被称之为矩阵的Null Space==



m*n的矩阵意思是 原始空间有n个基向量（原始空间是n维），m行表明这三个基向量在变换后仅用m个坐标表示，所以他们一定落在一个m维空间



叉积不具有交换位置后值不相等：V$\times$W=-W$\times$V 
V$\times$W：V在W右侧时，值为正，V在W左侧时，值为负
等于V和W组成矩阵的determinant
叉积得到的是一个vector，他的长度等于v和w围成的平行四边形的面积

Cramer‘s Rule
如果T(v)·T(w)=v·w for all v and w, 那么T is Orthonormal, 旋转矩阵

A·(x,y)=b

面积是y
原本(x,y)围成这么一个面积，A乘上它相当于做了一个det(A)的放缩面积

![image-20250411180517734](/Users/ianzhao/Desktop/MIT-Linear-Algebra-Notes/自己总结.assets/image-20250411180517734.png)

![image-20250411180107790](/Users/ianzhao/Desktop/MIT-Linear-Algebra-Notes/自己总结.assets/image-20250411180107790.png)



![image-20250411181043578](/Users/ianzhao/Desktop/MIT-Linear-Algebra-Notes/自己总结.assets/image-20250411181043578.png)

![image-20250411181136522](/Users/ianzhao/Desktop/MIT-Linear-Algebra-Notes/自己总结.assets/image-20250411181136522.png)







**LU分解**
高斯消元法本质上就是用消元矩阵对矩阵对乘积化简，E~1~E~2~A=U,得到U是一个上对角矩阵（理想），用逆矩阵可以表示成A=E^-1^U,很像LU的形式

这个E^-1^计算可以看得出来是个下三角矩阵 也就是L矩阵

Ax=b求解化简成 Lc=b,Ux=c的方程组，这种求解更快，由于L、U的矩阵形式，只需要代入求解即可出答案，降低了复杂度

如果在高斯消元法的过程中，要涉及到交换行得到U矩阵，我们在事前对A矩阵的行进行交换再做消去得到U（PA=A‘=LU)



向量空间：该空间对线性运算（相加，数乘）封闭， R^n^空间中包括所有的n维向量，每个列向量有n个分量，且分量均为实数

子空间取向量空间的一部分，在R^2^中 如果是第一象限这种是不行的，因为他不封闭，乘一个负数就延伸到第三象限了，而如果是一条过原点、一三象限的直线就可以是一个子空间，==子空间/向量空间一定过原点，零向量一定在向量空间中（任何向量乘上0都是零向量（属于数乘））==  
推广到R^2^的子空间就有 穿过原点的平面、穿过原点的直线、Z原点



两个子空间的并集肯定不是子空间了（不满足线性封闭），而两个子空间的交集肯定是子空间（满足线性封闭）

Ax=b可以理解成x **是矩阵** A **的列向量（基向量）的一个线性组合，组合后得到向量** b，而他们的解x构成一个个空间，b如果不为0，则x空间肯定不过原点，因此不够成一个向量空间，Ax=0中的解x构成一个零空间

Ax=b有解： 列空间角度：当且仅当b属于A的列空间时成立
                      线性组合角度：b必须是A各列的线性组合
                      A矩阵本身变换角度：如果A的各行线性组合得到零行，那么对b取相同的运算方式，必将得到自然数
零空间的维度时n-r（A的rank=r，自由列是n-r个，赋值之后就构成了零空间的n-r个基向量），反映的是A列向量线性组合得到零向量

**A的左零空间**：A^T^的零空间，反映A的行向量的线性组合得到零向量



行空间与零空间正交。A写成行向量的形式

![线性代数14](/Users/ianzhao/Desktop/MIT-Linear-Algebra-Notes/自己总结.assets/线性代数14.jpeg)



**投影向量**：
![IMG_8338C69A7927-1](/Users/ianzhao/Desktop/MIT-Linear-Algebra-Notes/自己总结.assets/IMG_8338C69A7927-1.jpeg)

P矩阵的rank为1
P矩阵转置前后与P一样：P^T^=P
投影多次结果与投影一次一样：P^2^=P

(I单位矩阵-P)也是一个投影矩阵
![image-20250419142921812](/Users/ianzhao/Desktop/MIT-Linear-Algebra-Notes/自己总结.assets/image-20250419142921812.png)

投影到一个面....（更加general）![IMG_0642B94AD2A1-1](/Users/ianzhao/Desktop/MIT-Linear-Algebra-Notes/自己总结.assets/IMG_0642B94AD2A1-1.jpeg)

**Change of basis：**
假如我们的基是(1,0),(0,1), 小A的基底在我们的角度/座标下表示的是（2，1）（-1，1），但是在他自己的座标下依然是（1，0）（0，1），如果要讲在小A的座标下表示的数（x,y)转变成我们的座标下的表示：需要$\[
\begin{bmatrix}
2 & -1 \\
1 & 1
\end{bmatrix}
\]$  作为A矩阵乘上（x,y）

而A^-1^做的事刚好相反![image-20250419153610482](/Users/ianzhao/Desktop/MIT-Linear-Algebra-Notes/自己总结.assets/image-20250419153610482.png)

 

如何翻译一个matrix：
1.最右边的向量是在小A的语言描述的
2.首先将其翻译成我们的语言（用我们的基底描述那个向量）
3.作用一个rotation矩阵，来达到一个旋转的效果（此时还是我们的语言）
4.最后把这个旋转的效果翻译成他们的语言，乘上A^-1^
![image-20250419154110803](/Users/ianzhao/Desktop/MIT-Linear-Algebra-Notes/自己总结.assets/image-20250419154110803.png)

==左边三个矩阵复合一下就是用小A的语言描述的线性变换==

施密特正交化**将一组线性无关的向量，通过逐步投影和减法的过程，转化成一组相同张成空间的正交基的方法**
![image-20250419155904680](/Users/ianzhao/Desktop/MIT-Linear-Algebra-Notes/自己总结.assets/image-20250419155904680.png)



**特征向量&特征值**（eigenvector&eigenvalue)
一个原始的基底下的某向量，在矩阵A的线性变换下往往会离开原本张成的直线，如果有一个向量很特殊，他在变换前后还是在原本张成的直线上，这意味着矩阵只是起到了一个拉伸或者压缩的效果

$A x = \lambda x$   $\lambda$ 就是那个特征值，表示放缩系数， x是eigenvector

向量数乘如何与矩阵乘法等价，可以理解成把基向量都扩大了$\lambda$倍，构成矩阵对角线都是$\lambda$ 

合并之后得到（A-$\lambda$)x=0,x如果非0，那么前面一项这个矩阵的线性变换是一个降维压缩的操作，意味着行列式=0

如果你在3D的空间下，这个特征向量就是旋转轴

**对角化**
如果我们用两个eigenvector（只有有足够多的eigenvector能够张成整个空间才可以）作为basis，把原本的变换转化成eigenbasis的语言($\text{NewTransform} \;=\; \mathrm{EV}^{-1}\,A\,\mathrm{EV}$)那么这个新的变换矩阵必然是是一个对角矩阵，大大减少了计算量，这个对角矩阵n次作用只需要把对角线上的值做一个n次方，之后如果想转会原标准坐标系$A^n \;=\; \mathrm{EV}\,\bigl(\text{NewTransform}^n\bigr)\,\mathrm{EV}^{-1}$( A^2 = EV * D * inv(EV) *  EV * D * inv(EV) = EV * D^2 * inv(EV)中间都被消了)

其中的NewTransform（D 对角矩阵）与原矩阵A相似

<img src="/Users/ianzhao/Desktop/MIT-Linear-Algebra-Notes/自己总结.assets/image-20250419164158198.png" alt="image-20250419164158198" style="zoom:50%;" />

A可以相似对角化 <=> A的特征向量可以构成一组基 <=> A有n个线性独立的特征向量<=n个互异的特征
如果算出两个相同的特征值，他们可能有两个线性独立的特征向量

**Jordan Canonical Form**（若尔当标准型）：当eigenvalue有多个一样值的时候（代数重数>1)，他们对应的特征向量不是都线性独立的时候(对应无关特征向量数量小于特征值重数），那么原矩阵就不与通常都对角阵相似，需要对角线上面一层是1，其他部分都是0，成为一个准对角矩阵
![image-20250420124847897](/Users/ianzhao/Desktop/MIT-Linear-Algebra-Notes/自己总结.assets/image-20250420124847897.png)

**只在对应同一个特征值（Eigenvalue）的小块（Jordan block）内部加 1**

若当块：![image-20250420125644217](/Users/ianzhao/Desktop/MIT-Linear-Algebra-Notes/自己总结.assets/image-20250420125644217.png)

有几个若当块，就有几个特征向量
x的代数重数=x出现的次数
x的几何重数=含有x的Jordan块数

**Trace**：方阵主对角线上所有元素的总和=eigenvalue的和  可以得到一个平均值m
**Determinant**: eigenvalue的乘积 p

（m+t)(m-t)=p,可以计算得到t,(m+t)和(m-t)就是特征值
在计算2维矩阵的特征值时：
![image-20250419174701786](/Users/ianzhao/Desktop/MIT-Linear-Algebra-Notes/自己总结.assets/image-20250419174701786.png)



**对称矩阵：**

* A=A^T^ 
* 有正交的特征向量

实对称矩阵的所有特征值都是实数；

==不同特征值对应的特征向量必然正交==，即使特征值相同，会有一整个平面的特征向量，选择其中垂直的一组向量即可（即使没有选择垂直的，也可以通过施密特正交化）

因此对称矩阵可以矩阵对角化：A=QDQ^-1^(Q的列向量标准正交，即列向量（都是特征向量）两两垂直且长度为0)，orthogonally diagonalizable

==对称矩阵一定可以写成一些互相垂直的投影矩阵的组合==：

![IMG_9285FC8E1F82-1](/Users/ianzhao/Desktop/MIT-Linear-Algebra-Notes/自己总结.assets/IMG_9285FC8E1F82-1.jpeg)

这些投影矩阵乘起来等于0

判断是否可以对角化：对称肯定可以；如果不对称，算重根的特征向量...

![image-20250420151023612](/Users/ianzhao/Desktop/MIT-Linear-Algebra-Notes/自己总结.assets/image-20250420151023612.png)

对称矩阵的正主元个数=正特征值个数
负主元个数=负特征值个数

==对称矩阵的主元乘积等于特征值的乘积==

**二次型（Quadratic function）**： f=x^T^Ax (A是一个对称矩阵) 二次型对应的矩阵表示不唯一，可以有无数种表示方式，只有表示 成对称矩阵时，二次型的矩阵表示才是唯一

**正定矩阵**：

二次型分类：

1. Positive definite f(x)=x^T^Ax>0 for x 不等于0 --> f(x) has the minimum at x=0
2. Negative definite f(x)=x^T^Ax<0 for x 不等于0 --> f(x) has the maximum at x=0
3. 还有不确定的情况，f(x)可能是正也可能是负

如果f(x)>=0 称其为semi- positive definite (在其他地方也能取到0，就是半正定)，半负定也是同理

*检测一个对称矩阵A是不是正定的*：

1. Test by Eigenvalues : A是正定<=> A的所有特征值都是positve的

2. Test by Pivot：A是正定<=>A所有的pivot都是positive（假设A没有行交换）

3.  Test by determinant of upper left submatrices : A是正定称<=> 所有任何左上方的小矩阵(

   $1\times1、2\times2、3\times3、……、n\times n$ 的左上角小矩阵的行列式)的行列式都是positive
   ![image-20250420163910376](/Users/ianzhao/Desktop/MIT-Linear-Algebra-Notes/自己总结.assets/image-20250420163910376.png)

正定对称矩阵的Cholesky 分解：
A=LL^T^  L是下三角阵，且对角元大于0
可以判断一个矩阵是否正定（程序）

**奇异值分解（SVD (Singular Value Decomposition) )**:

我们要先在行空间中找到一组正交基V，然后通过矩阵A的线性变换，得到列空间中一组正交基U
AV=U$\Sigma$  => A=U$\Sigma$V^-1^=U$\Sigma$V^T^

但是这种形式不太方便同时找到U与V：
A^T^A=V$\Sigma$^2^V^T^
AA^T^=U$\Sigma$^2^U^T^ 
A^T^A和AA^T^都是对称矩阵，V是对称矩阵的线性独立的特征向量标准化后构成的(也就是选的行空间中的基)，U也是特征向量标准化后构成的，二者求出的特征值应该是一样的，返回到原始的SVD分解需要开方它们的特征值

==奇异值是正的，从左上到右下，从大到小排列==

![image-20250421120811315](/Users/ianzhao/Desktop/MIT-Linear-Algebra-Notes/自己总结.assets/image-20250421120811315.png)

==矩阵A的秩== = $\Sigma$的正奇异值的个数

矩阵的外积：列矩阵$\times$行矩阵==Rank1矩阵
![image-20250421115831668](/Users/ianzhao/Desktop/MIT-Linear-Algebra-Notes/自己总结.assets/image-20250421115831668.png)

结果的rank从左到右不断增加 第一项最重要，不断的接近矩阵A

![image-20250421120243311](/Users/ianzhao/Desktop/MIT-Linear-Algebra-Notes/自己总结.assets/image-20250421120243311.png)

有点像泰勒展开，可以看成一个优化问题，最小化A与X之间的差距（受制于X的rank是k），X=A~k~是一个解，low-rank approximation低秩近似

可以用这个做图像压缩：
![image-20250421120632650](/Users/ianzhao/Desktop/MIT-Linear-Algebra-Notes/自己总结.assets/image-20250421120632650.png)



==矩阵的范数==
如何去衡量这种线性变换的长度呢？
1.induced norm(诱导范数)：所有的单位向量经过该线性变换后得到的最大长度的向量

1-范数：![image-20250421122324188](/Users/ianzhao/Desktop/MIT-Linear-Algebra-Notes/自己总结.assets/image-20250421122324188.png)

每一列模的最大和

矩阵的无穷范数是 ：最大一行的模的和
![image-20250421123121549](/Users/ianzhao/Desktop/MIT-Linear-Algebra-Notes/自己总结.assets/image-20250421123121549.png)

$\| A \|_{\infty} = \| A^T \|_{1}$



**Frobenius范数** ：所有的元素平方和再开方（类似于向量的模长）


